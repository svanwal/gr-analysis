{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82204626",
   "metadata": {},
   "source": [
    "## Importing modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a32d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svanwal/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import osmnx  as ox\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import folium\n",
    "import os.path\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Importing modules\n",
    "import gr_mapmatch # Contains functions that perform the map matching of roads\n",
    "import gr_placematch # Contains functions that perform the map matching of places\n",
    "import gr_utils # Contains useful geometry functions\n",
    "import gr_plot\n",
    "\n",
    "# Configuring modules & packages\n",
    "ox.settings.useful_tags_way = [\n",
    "    \"bridge\",\"tunnel\",\"name\",\"highway\",\"area\",\"landuse\",\"surface\",\"tracktype\"\n",
    "] # Configuring which parameters we want to obtain from OSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b93e47",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015a24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trailname = 'gr16' # Name of the hiking trail to be considered (will search for trail.csv or trail.gpx as sources)\n",
    "delta = 0.005 # Tolerance around bounding box per trail section [deg]\n",
    "points_per_batch = 100 # Subdivide the trail into batches of this many points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e8e6f",
   "metadata": {},
   "source": [
    "## Loading GPX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_gpx = 'data_input/' + trailname + '.gpx'\n",
    "filename_csv = 'data_output/' + trailname + '.csv'\n",
    "if not os.path.isfile(filename_csv): # The GPX file was not processed into a clean CSV file before\n",
    "    if not os.path.isfile(filename_gpx): # The GPX file does not exist, throw error\n",
    "        raise ValueError(f'The GPX file <{filename_gpx}> was not found! Please make sure it exists.')\n",
    "    else: # The GPX file exists, so convert it into a clean CSV file\n",
    "        print(f'Converting GPX file <{filename_gpx}> into cleaned CSV file <{filename_csv}>...')\n",
    "        gr_utils.process_gpx(filename_gpx,filename_csv)\n",
    "        print('Completed conversion.')\n",
    "print(f'Loading trail points from <{filename_gpx}>...')\n",
    "trail = pd.read_csv(filename_csv) # Now read the cleaned CSV file into a DataFrame (latitude, longitude, elevation)\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd817d",
   "metadata": {},
   "source": [
    "## Gathering road information from OSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1bdd1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling 0 of 60 that covers GPX track points 0 through 100...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 1 of 60 that covers GPX track points 100 through 200...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 2 of 60 that covers GPX track points 200 through 300...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 3 of 60 that covers GPX track points 300 through 400...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 4 of 60 that covers GPX track points 400 through 500...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 5 of 60 that covers GPX track points 500 through 600...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 6 of 60 that covers GPX track points 600 through 700...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 7 of 60 that covers GPX track points 700 through 800...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 8 of 60 that covers GPX track points 800 through 900...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 9 of 60 that covers GPX track points 900 through 1000...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 10 of 60 that covers GPX track points 1000 through 1100...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 11 of 60 that covers GPX track points 1100 through 1200...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 12 of 60 that covers GPX track points 1200 through 1300...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 13 of 60 that covers GPX track points 1300 through 1400...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 14 of 60 that covers GPX track points 1400 through 1500...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 15 of 60 that covers GPX track points 1500 through 1600...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 16 of 60 that covers GPX track points 1600 through 1700...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 17 of 60 that covers GPX track points 1700 through 1800...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 18 of 60 that covers GPX track points 1800 through 1900...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 19 of 60 that covers GPX track points 1900 through 2000...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 20 of 60 that covers GPX track points 2000 through 2100...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 21 of 60 that covers GPX track points 2100 through 2200...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 22 of 60 that covers GPX track points 2200 through 2300...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 23 of 60 that covers GPX track points 2300 through 2400...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 24 of 60 that covers GPX track points 2400 through 2500...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 25 of 60 that covers GPX track points 2500 through 2600...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 26 of 60 that covers GPX track points 2600 through 2700...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 27 of 60 that covers GPX track points 2700 through 2800...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 28 of 60 that covers GPX track points 2800 through 2900...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 29 of 60 that covers GPX track points 2900 through 3000...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 30 of 60 that covers GPX track points 3000 through 3100...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 31 of 60 that covers GPX track points 3100 through 3200...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 32 of 60 that covers GPX track points 3200 through 3300...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 33 of 60 that covers GPX track points 3300 through 3400...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 34 of 60 that covers GPX track points 3400 through 3500...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 35 of 60 that covers GPX track points 3500 through 3600...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 36 of 60 that covers GPX track points 3600 through 3700...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 37 of 60 that covers GPX track points 3700 through 3800...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 38 of 60 that covers GPX track points 3800 through 3900...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 39 of 60 that covers GPX track points 3900 through 4000...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 40 of 60 that covers GPX track points 4000 through 4100...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 41 of 60 that covers GPX track points 4100 through 4200...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 42 of 60 that covers GPX track points 4200 through 4300...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 43 of 60 that covers GPX track points 4300 through 4400...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 44 of 60 that covers GPX track points 4400 through 4500...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 45 of 60 that covers GPX track points 4500 through 4600...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 46 of 60 that covers GPX track points 4600 through 4700...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 47 of 60 that covers GPX track points 4700 through 4800...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 48 of 60 that covers GPX track points 4800 through 4900...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 49 of 60 that covers GPX track points 4900 through 5000...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 50 of 60 that covers GPX track points 5000 through 5100...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 51 of 60 that covers GPX track points 5100 through 5200...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 52 of 60 that covers GPX track points 5200 through 5300...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 53 of 60 that covers GPX track points 5300 through 5400...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 54 of 60 that covers GPX track points 5400 through 5500...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 55 of 60 that covers GPX track points 5500 through 5600...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 56 of 60 that covers GPX track points 5600 through 5700...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 57 of 60 that covers GPX track points 5700 through 5800...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 58 of 60 that covers GPX track points 5800 through 5900...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 59 of 60 that covers GPX track points 5900 through 6000...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 60 of 60 that covers GPX track points 6000 through 6052...\n",
      "   This batch was processed before, skipping.\n"
     ]
    }
   ],
   "source": [
    "# TODO - make this optional only if the roads file is not found!!!\n",
    "\n",
    "# Matching GPX track to OSM network (uses _osm_network_download under the hood)\n",
    "n_trail = len(trail) # Number of GPX points in the trail\n",
    "n_batch = int(np.ceil(trail.shape[0]/points_per_batch)) # Number of batches to be run\n",
    "for b in range(n_batch): # Using batch counter b\n",
    "    \n",
    "    # Define the range of GPX points to process in the current batch\n",
    "    n1 = b*points_per_batch # First point of this batch\n",
    "    n2 = min(n1 + points_per_batch, n_trail) # Last point of this batch (clipped)\n",
    "    trail_section = trail.loc[n1:n2] # Select that range of GPX points\n",
    "    trail_coords  = gr_mapmatch.trail_to_coords(trail_section) # Convert the points into a list of [lat, lon] pairs\n",
    "    \n",
    "    # Check if this batch was processed before\n",
    "    # TODO - update name to have _roads_ in there\n",
    "    batch_out = f'cache/{trailname}_{n1}to{n2}.csv'\n",
    "    print(f'Handling {b} of {n_batch-1} that covers GPX track points {n1} through {n2}...')\n",
    "    if os.path.isfile(batch_out): # It already exists\n",
    "        print('   This batch was processed before, skipping.')\n",
    "    else: # It does not exist, so process it\n",
    "        network, segment_list = gr_mapmatch.match_batch(trail_section, trail_coords, delta)\n",
    "        gr_utils.write_batch(batch_out, segment_list)\n",
    "        print('   Finished this batch.')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7e50b",
   "metadata": {},
   "source": [
    "## Merging road information & removing backtracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7157cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged section file...\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "filename_roads = 'cache/' + trailname + '_roads.csv'\n",
    "if not os.path.isfile(filename_roads): # The merged file does not exist\n",
    "    print('Merged section file was not found, merging and saving...')\n",
    "    data_roads_raw = gr_utils.merge_roads(trailname, trail, points_per_batch) # Merge the different sections\n",
    "    data_roads = gr_mapmatch.remove_repeat_segments(data_roads_raw) # Remove backtracked sections\n",
    "    gr_utils.write_roads(trailname, data_roads) # Write the merged sections\n",
    "    print('Saved.')\n",
    "else: # The merged file does exist\n",
    "    print('Loading merged section file...')\n",
    "    data_roads = gr_utils.read_roads(trailname) # Read the merged sections\n",
    "    print('Loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289f2ec",
   "metadata": {},
   "source": [
    "## Gathering place information from OSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "395f5315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling 0 of 62 that covers road segments 0 through 99...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 1 of 62 that covers road segments 100 through 199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 2 of 62 that covers road segments 200 through 299...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 3 of 62 that covers road segments 300 through 399...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 4 of 62 that covers road segments 400 through 499...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 5 of 62 that covers road segments 500 through 599...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 6 of 62 that covers road segments 600 through 699...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 7 of 62 that covers road segments 700 through 799...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 8 of 62 that covers road segments 800 through 899...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 9 of 62 that covers road segments 900 through 999...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 10 of 62 that covers road segments 1000 through 1099...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 11 of 62 that covers road segments 1100 through 1199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 12 of 62 that covers road segments 1200 through 1299...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 13 of 62 that covers road segments 1300 through 1399...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 14 of 62 that covers road segments 1400 through 1499...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 15 of 62 that covers road segments 1500 through 1599...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 16 of 62 that covers road segments 1600 through 1699...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 17 of 62 that covers road segments 1700 through 1799...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 18 of 62 that covers road segments 1800 through 1899...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 19 of 62 that covers road segments 1900 through 1999...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 20 of 62 that covers road segments 2000 through 2099...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 21 of 62 that covers road segments 2100 through 2199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 22 of 62 that covers road segments 2200 through 2299...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 23 of 62 that covers road segments 2300 through 2399...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 24 of 62 that covers road segments 2400 through 2499...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 25 of 62 that covers road segments 2500 through 2599...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 26 of 62 that covers road segments 2600 through 2699...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 27 of 62 that covers road segments 2700 through 2799...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 28 of 62 that covers road segments 2800 through 2899...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 29 of 62 that covers road segments 2900 through 2999...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 30 of 62 that covers road segments 3000 through 3099...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 31 of 62 that covers road segments 3100 through 3199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 32 of 62 that covers road segments 3200 through 3299...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 33 of 62 that covers road segments 3300 through 3399...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 34 of 62 that covers road segments 3400 through 3499...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 35 of 62 that covers road segments 3500 through 3599...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 36 of 62 that covers road segments 3600 through 3699...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 37 of 62 that covers road segments 3700 through 3799...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 38 of 62 that covers road segments 3800 through 3899...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 39 of 62 that covers road segments 3900 through 3999...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 40 of 62 that covers road segments 4000 through 4099...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 41 of 62 that covers road segments 4100 through 4199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 42 of 62 that covers road segments 4200 through 4299...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 43 of 62 that covers road segments 4300 through 4399...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 44 of 62 that covers road segments 4400 through 4499...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 45 of 62 that covers road segments 4500 through 4599...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 46 of 62 that covers road segments 4600 through 4699...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 47 of 62 that covers road segments 4700 through 4799...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 48 of 62 that covers road segments 4800 through 4899...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 49 of 62 that covers road segments 4900 through 4999...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 50 of 62 that covers road segments 5000 through 5099...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 51 of 62 that covers road segments 5100 through 5199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 52 of 62 that covers road segments 5200 through 5299...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 53 of 62 that covers road segments 5300 through 5399...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 54 of 62 that covers road segments 5400 through 5499...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 55 of 62 that covers road segments 5500 through 5599...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 56 of 62 that covers road segments 5600 through 5699...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 57 of 62 that covers road segments 5700 through 5799...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 58 of 62 that covers road segments 5800 through 5899...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 59 of 62 that covers road segments 5900 through 5999...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 60 of 62 that covers road segments 6000 through 6099...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 61 of 62 that covers road segments 6100 through 6199...\n",
      "   This batch was processed before, skipping.\n",
      "Handling 62 of 62 that covers road segments 6200 through 6257...\n",
      "   This batch was processed before, skipping.\n"
     ]
    }
   ],
   "source": [
    "## Matching GPX track to OSM places (uses _osm_place_download under the hood)\n",
    "n_roads = len(data_roads) # Number of segments in data_roads\n",
    "points_per_batch_places = 100 # Subdivide the trail into batches of this many segments\n",
    "n_batch_places = int(np.ceil(n_roads/points_per_batch_places)) # Number of batches to be run\n",
    "delta_places = 0.005 # bbox delta in deg\n",
    "data_roads['dev_dist'] = 0.0 # filling\n",
    "for b in range(n_batch_places): # Using batch counter b\n",
    "    \n",
    "    # Define the range of segments to process in the current batch\n",
    "    n1 = b*points_per_batch_places # First point of this batch\n",
    "    n2 = min(n1 + points_per_batch_places, n_roads) - 1 # Last point of this batch (clipped)\n",
    "\n",
    "    # Check if this batch was processed before\n",
    "    batch_out = f'cache/{trailname}_places_{n1}to{n2}.csv'\n",
    "    print(f'Handling {b} of {n_batch_places-1} that covers road segments {n1} through {n2}...')\n",
    "    if os.path.isfile(batch_out): # It already exists\n",
    "        print('   This batch was processed before, skipping.')\n",
    "    else: # It does not exist, so process it (use loc to avoid selection error)\n",
    "        data_roads.loc[n1:n2,'dev_dist'] = gr_placematch.match_batch(data_roads.loc[n1:n2], delta_places)\n",
    "        gr_utils.write_batch_places(batch_out, data_roads.loc[n1:n2])\n",
    "        print('   Finished this batch.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32922059",
   "metadata": {},
   "source": [
    "## Merging place information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd3d9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged section file...\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "filename_places = 'cache/' + trailname + '_places.csv'\n",
    "if not os.path.isfile(filename_places): # The merged file does not exist\n",
    "    print('Merged places file was not found, merging...')\n",
    "    data_places = gr_utils.merge_places(trailname, data_roads, points_per_batch_places) # Merge the different sections\n",
    "    print('Saving...')\n",
    "    gr_utils.write_places(trailname, data_places) # Write the merged sections\n",
    "    print('Saved.')\n",
    "else: # The merged file does exist\n",
    "    print('Loading merged section file...')\n",
    "    data_places = gr_utils.read_places(trailname) # Read the merged sections\n",
    "    print('Loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b312b617",
   "metadata": {},
   "source": [
    "## Establishing paving/traffic/development status & GR type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d15ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'cache/{trailname}_places.csv'\n",
    "data_places = pd.read_csv(filename,dtype={'highway':str, 'surface': str, 'tracktype':str},index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a14a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6258 entries, 0 to 6502\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   x0               6258 non-null   float64\n",
      " 1   y0               6258 non-null   float64\n",
      " 2   x1               6258 non-null   float64\n",
      " 3   y1               6258 non-null   float64\n",
      " 4   d_cart           6258 non-null   float64\n",
      " 5   d_osm            6258 non-null   float64\n",
      " 6   highway          6258 non-null   object \n",
      " 7   surface          6258 non-null   object \n",
      " 8   tracktype        6258 non-null   object \n",
      " 9   first_highway    6258 non-null   object \n",
      " 10  first_surface    6258 non-null   object \n",
      " 11  first_tracktype  6258 non-null   object \n",
      " 12  paved            6258 non-null   int64  \n",
      " 13  traffic          6258 non-null   int64  \n",
      "dtypes: float64(6), int64(2), object(6)\n",
      "memory usage: 862.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data_places.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7482acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish paving status\n",
    "tracktype_p0 = ['grade4','grade5']\n",
    "tracktype_p1 = ['grade2','grade3']\n",
    "tracktype_p2 = ['grade1']\n",
    "surface_p0 = ['ground','grass','dirt','sand','earth','mud']\n",
    "surface_p1 = ['unpaved','gravel','fine_gravel','wood','compacted','rocks','pebblestone','woodchips','snow','ice','salt']\n",
    "highway_p1 = ['track','path','footway','bridleway']\n",
    "# Establish paved status\n",
    "data_places = gr_mapmatch.get_paved_type(data_places,tracktype_p0,tracktype_p1,tracktype_p2,surface_p0,surface_p1,highway_p1)\n",
    "# Establish traffic status\n",
    "types_slow = ['pedestrian','track','footway','bridleway','steps','corridor','path']\n",
    "types_heavy = ['motorway','trunk','primary','secondary','tertiary']\n",
    "data_places = gr_mapmatch.get_traffic_type(data_places,types_slow,types_heavy)\n",
    "# Establish development status\n",
    "tol_d = 0.5\n",
    "data_places = gr_placematch.get_development_type(data_places,tol_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbef7c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6013 entries, 0 to 6012\n",
      "Data columns (total 17 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       6013 non-null   int64  \n",
      " 1   x0               6013 non-null   float64\n",
      " 2   y0               6013 non-null   float64\n",
      " 3   x1               6013 non-null   float64\n",
      " 4   y1               6013 non-null   float64\n",
      " 5   d_cart           6013 non-null   float64\n",
      " 6   d_osm            6013 non-null   float64\n",
      " 7   highway          6013 non-null   object \n",
      " 8   surface          6013 non-null   object \n",
      " 9   tracktype        6013 non-null   object \n",
      " 10  dev_dist         6013 non-null   float64\n",
      " 11  first_highway    6013 non-null   object \n",
      " 12  first_surface    6013 non-null   object \n",
      " 13  first_tracktype  6013 non-null   object \n",
      " 14  paved            6013 non-null   int64  \n",
      " 15  traffic          6013 non-null   int64  \n",
      " 16  development      6013 non-null   bool   \n",
      "dtypes: bool(1), float64(7), int64(3), object(6)\n",
      "memory usage: 933.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_places.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e644077",
   "metadata": {},
   "source": [
    "## Saving completed data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24770a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e7f5d87",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c488ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Development status\n",
    "tol_d = 0.5 # Consider a segment developed if it lies closer than tol_d to a developed area\n",
    "filepath = gr_plot.show_development(data_places,tol_d)\n",
    "IFrame(filepath, width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4911ad21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a8066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
