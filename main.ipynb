{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82204626",
   "metadata": {},
   "source": [
    "## Importing modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a32d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svanwal/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import osmnx  as ox\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import folium\n",
    "import os.path\n",
    "import shapely\n",
    "import geopandas as gpd\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Importing modules\n",
    "import gr_mapmatch # Contains functions that perform the map matching of roads\n",
    "import gr_placematch # Contains functions that perform the map matching of places\n",
    "import gr_utils # Contains useful geometry functions\n",
    "import gr_plot # Contains plotting routines\n",
    "import gr_process\n",
    "\n",
    "# Configuring modules & packages\n",
    "ox.settings.useful_tags_way = [\n",
    "    \"bridge\",\"tunnel\",\"name\",\"highway\",\"area\",\"landuse\",\"surface\",\"tracktype\"\n",
    "] # Configuring which parameters we want to obtain from OSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b93e47",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "015a24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "trailname = 'gr16' # Name of the hiking trail to be considered (will search for trail.csv or trail.gpx as sources)\n",
    "# Settings for trail2roads\n",
    "points_per_batch = 100 # Subdivide the trail into batches of this many points\n",
    "delta = 0.005 # Tolerance around bounding box per trail section [deg]\n",
    "# Settings for roads2places\n",
    "points_per_batch_places = 100 # Subdivide the trail into batches of this many segments\n",
    "delta_places = 0.005 # bbox delta in deg\n",
    "# Settings for places2processed\n",
    "tracktype_p0 = ['grade4','grade5']\n",
    "tracktype_p1 = ['grade2','grade3']\n",
    "tracktype_p2 = ['grade1']\n",
    "surface_p0   = ['ground','grass','dirt','sand','earth','mud']\n",
    "surface_p1   = ['unpaved','gravel','fine_gravel','wood','compacted','rocks','pebblestone','woodchips','snow','ice','salt']\n",
    "highway_p1   = ['track','path','footway','bridleway']\n",
    "tol_d = 0.5 # Consider a segment developed if it lies closer than tol_d to a developed area\n",
    "types_slow = ['pedestrian','track','footway','bridleway','steps','corridor','path']\n",
    "types_heavy = ['motorway','trunk','primary','secondary','tertiary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e8e6f",
   "metadata": {},
   "source": [
    "## Loading GPX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "667a640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trail points from <data_input/gr16.gpx>...\n",
      "Finished loading.\n"
     ]
    }
   ],
   "source": [
    "filename_gpx = 'data_input/' + trailname + '.gpx'\n",
    "filename_csv = 'data_output/' + trailname + '.csv'\n",
    "if not os.path.isfile(filename_csv): # The GPX file was not processed into a clean CSV file before\n",
    "    if not os.path.isfile(filename_gpx): # The GPX file does not exist, throw error\n",
    "        raise ValueError(f'The GPX file <{filename_gpx}> was not found! Please make sure it exists.')\n",
    "    else: # The GPX file exists, so convert it into a clean CSV file\n",
    "        print(f'Converting GPX file <{filename_gpx}> into cleaned CSV file <{filename_csv}>...')\n",
    "        gr_utils.process_gpx(filename_gpx,filename_csv)\n",
    "        print('Completed conversion.')\n",
    "print(f'Loading trail points from <{filename_gpx}>...')\n",
    "trail = pd.read_csv(filename_csv) # Now read the cleaned CSV file into a DataFrame (latitude, longitude, elevation)\n",
    "print('Finished loading.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd817d",
   "metadata": {},
   "source": [
    "## Gathering ROAD data from OSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44913992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged ROADS file...\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "filename_roads = 'cache/' + trailname + '_roads.csv'\n",
    "\n",
    "if not os.path.isfile(filename_roads): # The merged ROADS file does not exist, construct it\n",
    "    \n",
    "    print('Merged ROADS file was not found, merging and saving...')\n",
    "    gr_mapmatch.trail2roads(trailname, trail, points_per_batch, delta) # Main batch processor\n",
    "    data_roads_raw = gr_utils.merge_roads(trailname, trail, points_per_batch) # Merge the different sections\n",
    "    data_roads = gr_mapmatch.remove_repeat_segments(data_roads_raw) # Remove backtracked sections\n",
    "    gr_utils.write_roads(trailname, data_roads) # Write the merged ROADS data\n",
    "#     print('Saved.')\n",
    "\n",
    "else: # The merged ROADS file does exist, just load it\n",
    "    \n",
    "    print('Loading merged ROADS file...')\n",
    "    data_roads = gr_utils.read_roads(trailname) # Read the merged sections\n",
    "    print('Loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e289f2ec",
   "metadata": {},
   "source": [
    "## Gathering PLACE data from OSM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b51ac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading merged PLACES file...\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "filename_places = 'cache/' + trailname + '_places.csv'\n",
    "\n",
    "if not os.path.isfile(filename_places): # The merged PLACES file does not exist\n",
    "    \n",
    "    print('Merged PLACES file was not found, merging and saving...')\n",
    "    gr_placematch.roads2places(trailname,data_roads,points_per_batch_places, delta_places)\n",
    "    data_places = gr_utils.merge_places(trailname, data_roads, points_per_batch_places) # Merge the different sections\n",
    "    gr_utils.write_places(trailname, data_places) # Write the merged PLACES data\n",
    "    print('Saved.')\n",
    "    \n",
    "else: # The merged PLACES file does exist\n",
    "    \n",
    "    print('Loading merged PLACES file...')\n",
    "    data_places = gr_utils.read_places(trailname) # Read the merged PLACES file\n",
    "    print('Loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb2b8c",
   "metadata": {},
   "source": [
    "## Evaluating PROCESSED properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f33ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PROCESSED file was not found, processing and saving...\n",
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "filename_processed = 'data_output/' + trailname + '_processed.csv'\n",
    "\n",
    "if not os.path.isfile(filename_processed): # The PROCESSED file does not exist\n",
    "    \n",
    "    print('The PROCESSED file was not found, processing and saving...')\n",
    "    data = gr_process.places2processed(data_places,tol_d,types_slow,types_heavy,tracktype_p0,tracktype_p1,tracktype_p2,surface_p0,surface_p1,highway_p1) # Determine traffic/development/paved status & GR types\n",
    "    gr_utils.write_processed(trailname, data) # Write the processed data\n",
    "    print('Saved.')\n",
    "    \n",
    "else: # The PROCESSED file does exist\n",
    "    \n",
    "    print('The PROCESSED file already exists, so nothing needs to be done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3fcef5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
